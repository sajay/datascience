Data science
---------------------
1)Problem statement

a)What
b)Data

2)Platform / Infrastructure/Tools
Where do I run and what tools, software packages do I use

etl
customer data; 3 sources	

3)Machine learning
-How ?
-what algorithms apply where

know why 


4)Present the Solution to the problem that can be run on the platform

-----------------
Workflow stages
---------------------
The competition solution workflow goes through seven stages described in the Data Science Solutions book.

1)Question or problem definition.
2)Acquire training and testing data.
3)Wrangle, prepare, cleanse the data.
4)Analyze, identify patterns, and explore the data.
5)Model, predict and solve the problem.
Math
6)Visualize, report, and present the problem solving steps and final solution.
7)Supply or submit the results.

The workflow indicates general sequence of how each stage may follow the other. However there are use cases with exceptions.

-We may combine mulitple workflow stages. We may analyze by visualizing data.
-Perform a stage earlier than indicated. We may analyze data before and after wrangling.
-Perform a stage multiple times in our workflow. Visualize stage may be used multiple times.
-Drop a stage altogether. We may not need supply stage to productize or service enable our dataset for a competition.


The data science solutions workflow solves for seven major goals.
------------------------------------------------------------------

1)Classifying:
 We may want to classify or categorize our samples. 
 We may also want to understand the implications or correlation of different classes with our solution goal.

2)Correlating:
One can approach the problem based on available features within the training dataset. Which features within the dataset contribute significantly to our solution goal? 
Statistically speaking is there a correlation among a feature and solution goal? As the feature values change does the solution state change as well, and visa-versa? 

This can be tested both for numerical and categorical features in the given dataset. We may also want to determine correlation among features other than survival for subsequent goals and workflow stages. Correlating certain features may help in creating, completing, or correcting features.

3)Converting:
 For modeling stage, one needs to prepare the data. Depending on the choice of model algorithm one may require all features to be converted to numerical equivalent values. So for instance converting text categorical values to numeric values.

4)Completing:
 Data preparation may also require us to estimate any missing values within a feature. Model algorithms may work best when there are no missing values.

5)Correcting: 
We may also analyze the given training dataset for errors or possibly innacurate values within features and try to corrent these values or exclude the samples containing the errors. One way to do this is to detect any outliers among our samples or features. We may also completely discard a feature if it is not contribting to the analysis or may significantly skew the results.

6)Creating:
 Can we create new features based on an existing feature or a set of features, such that the new feature follows the correlation, conversion, completeness goals.

7)Charting:
 How to select the right visualization plots and charts depending on nature of the data and the solution goals. A good start is to read the Tableau paper on Which chart or graph is right for you?.

https://blog.patricktriest.com/titanic-machine-learning-in-python/

https://www.kaggle.com/bemmerdinger/titanic-data-science-solutions

http://www.r2d3.us/

https://towardsdatascience.com/from-business-question-to-data-science-task-55a49f471a0c

https://towardsdatascience.com/how-to-ask-questions-data-science-can-solve-e073d6a06236


Steps (as per Blooms taxonomy)
---------------------------------

We should ask questions first. 
Data questions follow a continuum from easy to difficult. Asking many small questions will lead to progress and lead you toward big insights you never expected.


1)Remember — Who, what, where, or when did something happen?

How did the user find the website
What search criteria did the user use?


2)Understand — Can you summarize what happened?

Use average, SD to aggregate & summarize


3)Apply — What happens when …?

a)Generalize using Hypothesis testing, cross validate

b)Use Regression techniques : 
For instance: Is there a relationship between time spent under the sun and the height of a plant?
This is a regression problem, Y = f(X). Y = height of plant. F represents any model that captures the relationship. X = the quantity of time the plant has spent in sunlight.

c)Use classification techniques:
For instance: 

i)Will this air conditioner fail in the next 3 years: Yes or no?

This is a classification problem, Y = f(X). Y = {fail, don’t fail}. F represents any model that captures the relationship. X is data that records the history of air conditioner failures and related characteristics.

ii)Which animal is in a given image?

This is also a classification problem, Y = f(x), sometimes called multi-class classification. Y = {dog, cat, horse, other}. F represents any model that captures the relationship. The data, X, would be images encoded into tabular form.

iii)What is the likelihood that this customer will buy?

This is a classification problem, Y=f(X), Y = {buy, not buy}. X is data related to customer purchasing habits. Many algorithms will be able to give you the probability of falling into a particular class.

iv)Is this bank transaction fraudulent?

This is a classification problem, Y=f(x). Y = {fraudulent, not fraudulent}. X is bank transaction data. Anomaly detection may also handle this problem. Anomaly detection may work even if you don’t have past data that labels fraud, but it’s a harder problem.


4)Analyze — What are the key parts and relationships of …?

To answer analysis questions you break your data apart and look for patterns. 
Feature selection, dimensionality reduction, and clustering are the key tools.

a)Regression w Feature Selection:

For instance : What factors best predict electricity demand?

This is a regression problem with feature selection, Y=f(X). Y = quantity of electricity demanded. F represents any model that captures the relationship between your data and electricity demanded. X probably has the features price, temperature, season, region, and many other features. To find the most important factors we use feature selection to remove factors that don’t predict electricity demand.

b)Classification w Feature Selection:

For instance : What are the key differences between apples and oranges?

This is a classification problem with feature selection, Y=f(X). Y = {apples, oranges}. F represents any model that captures the relationships in your data. X has many characteristics such as height, weight, color, taste, and toughness. Feature selection finds the characteristics that best distinguish apples and oranges.

c)Clustering

For instance: Which groups of sensors in my HVAC system tend to vary with (and against) each other?

This is a clustering problem because we group similar sensors with each other. We organize the data with sensors as rows and ‘time of reading’ as columns.

d)Dimentionality Reduction problem

For instance : What combination of sensors in my HVAC system best displays the overall health of the system?

This is a dimensionality reduction problem. We take a wealth of data and turn it into a few key performance indicators. In this case, we organize the data with different sensors as different columns.

e)Which viewers like the same kind of movies?

This is odd because we try to group similar users and similar movies. This is typical for a recommendation engine. We can also write a simpler application as “Does this user like this group of movies?” or even simpler as “Will this user like this movie?”

f)What leadership practices do successful CEOs have in common?

This looks like a grouping question at first. It comes back to key differences once you read between the lines. All successful CEOs eat, so do all unsuccessful CEOs. We are much more interested in what predicts success.

5)Evaluate — Is this the best approach?

To answer evaluation questions, you need to extrapolate your data into complex hypothetical cases.

For example: Can we save money by pricing different products better?

This comes down to scenario analysis. We come up with several pricing schemes, then predict their effects using models. This will likely involve classification, regression, and critical thinking.

6) Create — Can you predict what will happen to … under new conditions?

Creation questions ask you to create new optimal solutions.

For example:
a)What route should my delivery truck take?
This is a well known optimization problem. The main criteria is to minimize money spent on fuel while making all deliveries on time.

b)Where should we set up our new location?

Here we need to optimize to a specific criteria. A simple one is to maximize profits, but in reality, more goes into consideration. To write an optimization we need to be able to evaluate locations. Which takes us back to the apply, analyze, and evaluate phases.

c)Where should I place this ad on the webpage so that the viewer is most likely to click it?

You might write this as an optimization, but there are better options. It is inexpensive to move an ad around and see how it performs. That means we can experiment rather than decide ahead of time. Try to position the ad and test its effectiveness. You can even automate this process through A/B testing or reinforcement learning.

e)Should my automated cooling and heating system adjust the temperature higher, lower, or leave it where it is?

This is a good area for reinforcement learning. Your cooling system adjusts to input data such as electricity price, time of day, and your stated preferences.

Misc Notes
-------------

Step 1: data exploration
-get a feel for the data
-null-data gaps
-pca, mean, median, sd

Sometimes you need to use synthetic data generation from summarized stats for  sensitive data

Step 2 : Feature selection/Data Cleansing
-basic stats 
-how do u validate some of the model selection

eg:Predict attrition of customers

Other:
-----
-h20 is used to deploy ds models to prod

Note :
data engg: ETL, provide data for data science 
